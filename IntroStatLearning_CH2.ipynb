{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc642f9b",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "Statistical learning refers to a set of tools for modeling and understanding complex datasets. It is a recently developed area in statistics and blends parallel developments in computer science and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8d631",
   "metadata": {},
   "source": [
    "## Chapter 1. Introduction\n",
    "\n",
    "*Statistical learning* refers to a vast set of tools for *understanding data*. These tools can be classified as *supervised* or *unsupervised*. Broadly speaking, supervised statistical learning involves building a statistical model for predicting, or estimating, an *output* based on one or more *inputs*. With unsupervised learning, there are inputs but no supervising outputs; but we can still learn relationships and structure from such data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727686e8",
   "metadata": {},
   "source": [
    "## Chapter 2. Statistical Learning\n",
    "\n",
    "### 2.1 What is Statistical Learning?\n",
    "Our goal is use *prior* data to predict *future data* or to learn about the *relationships* between different variables in the data. Suppose we observe a response $Y$ and $p$ different predictors, $X_1, X_2, ..., X_p$. We further assume some relationship between $Y$ and $X = (X_1, X_2, ..., X_p)$, which is expressed in the general form $$Y = f(X) + \\epsilon$$\n",
    "\n",
    "Here $f$ is some fixed but unknown function of $X$ and $\\epsilon$ is a random error term which is independent of $X$ and has mean zero. \n",
    "\n",
    "In essence, **statistical learning refers to a set of approaches for estimating $f$.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513fe14f",
   "metadata": {},
   "source": [
    "### 2.1.1 Why estimate $f$?\n",
    "There are two main reasons we may wish to estimate $f$: prediction and inference. \n",
    "\n",
    "###### Prediction\n",
    "In many situations, a set of inputs $X$ are readily available, but the output Y cannot be easily obtained. In this setting, we predict $Y$ using $$ \\hat{Y} = \\hat{f}(X),$$ where $\\hat{f}$ represents the resulting prediction for $f$, and $\\hat{Y}$ represents the resulting prediction for $Y$. \n",
    "\n",
    "The accuracy of $\\hat{Y}$ as a prediction for $Y$ depends on two quantities: *reducible error* and *irreducible error*. In general, $\\hat{f}$ will not be a perfect estimate for $f$, and this inaccuracy will introduce some error into our prediction. This error is *reduceable* because we can potentially improve the accuracy of $\\hat{f}$ by using the most appropriate statistical learning technique to estiamte $\\hat{f}$.\n",
    "\n",
    "The variability associated with $\\epsilon$, which \"random\" and out of our control, will still introduce error in how well we can estimate $Y$ and is thus refered to as *irreducible error*.\n",
    "\n",
    "Consider a given estimate $\\hat{f}$ and a set of predictions $X$ which yeilds the prediction $\\hat{Y} = \\hat{f}(X)$. Then the expected value of the difference between $Y$ and $\\hat{Y}$, or the expected error in our prediction, is equal to $$E(Y - \\hat{Y})^2 = E[f(X) + \\epsilon - \\hat{f}(X)]^2$$ $$= [f(X) - \\hat{f}(X)]^2 + Var(\\epsilon)$$\n",
    "\n",
    "Therefore, **our goal is to esitmate $f$ with the aim of minimizing the reducible error.**\n",
    "\n",
    "###### Inference\n",
    "We are often interested in understanding the way that $Y$ is affected as $X_1, X_2, ..., X_p$ change. In this situation we wish to edtimate $f$, but out goal is to understand the relationship between $X$ and $Y$. More specifically, to understand how $Y$ changes as a function of $X_1, X_2, ..., X_p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e346875",
   "metadata": {},
   "source": [
    "### 2.1.2 How do we estimate $f$?\n",
    "We will always assume we have observed a set of $n$ different data points. These data points, or observations, will be called *training data* because we will use these observations to train, or teach, our method of how to estimate $\\hat{f}$. Let $x_{ij}$ represent the value of the $j$th predictor for the $i$th data point where $i = 1, 2, ..., n$ and $j = 1, 2, ..., p$. Therefore $n$ represents the number of observations, each with $p$ different variables. Then let $y_i$ represent the response variable, or output, for the $i$th observation. Then our training data consists of ${(x_1, y_1), ..., (x_n, y_n)}$ ... where $x_i = (x_{i1}, x_{i2}, ..., x_{ip})^T$. The goal is to apply a statistical learning method to the training data in order to estimate the unknown function $f$. In other words, we want to find a function $\\hat{f}$ such that $Y \\approx \\hat{f}(X)$ for any observation $(X,Y)$. \n",
    "\n",
    "Broadly speaking, most statistical learning methods can be characterized as either *parametric or non-parametric*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a80875",
   "metadata": {},
   "source": [
    "###### Parametric Models\n",
    "Parametric models involve a two-step model based approach. \n",
    "1. Make an assumption about the functional form of $f$. For example, a common assumption is that $f$ is linear in $X$: $$f(X) = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$$\n",
    "2. Select a procedure that used the training data to *fit* or *train* the model. In the case of the linear model, we need to estimate the parameters $\\beta_0, \\beta_1, ..., \\beta_p$ such that $$Y \\approx \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$$ For example, the most common approach to fitting the linear model shown above is referred to as *(ordinary) least squares. \n",
    "\n",
    "This approach is referred to as *parametric* because it reduces the problem of estimating $f$ down to estimating a set of parameters. Assuming a parametric form of $f$ simplifies the problem of estimating $f$ because it is generally much easier to estimate a set of paramters than it is to fit an entirely arbitrary function $f$. The potential disadvantage of a parametric approach is that the model we choose will usually not match the true unknown form of $f$. Id the choosen form of $f$ is too far from the true form of $f$, then our estimate will be poor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f6b94",
   "metadata": {},
   "source": [
    "###### Non-parametric Models\n",
    "Non-parametric methods do not explicitly assume the functional form of $f$. Instead, they seek an estimate of $f$ that gets as close to the training data points as possbile without being to rough of wiggly. By avoiding the assumption of a particular functional form of $f$, they have the potential to accuractely fit a widers range of possible shapes for $f$. Non-parametric approaches do suffer from a major disadvantage: since they do not reduce the problem of estimating $f$ to a small number of parameters, a very large number of observations is required in order to obtain an accurate estimate for $f$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946bdbff",
   "metadata": {},
   "source": [
    "### 2.1.3 The Trade-Off Between Prediction Accuracy and Model Interpretability\n",
    "One might reasonably ask: *Why would we ever choose a less accurate model instead of a more accurate model?*. If we are interested in inference, then restrictive/less accurate models are more much interpretable. Complex models lead to complicated estimates of $f$ that are difficult to understand how any individual predictor is associated with the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8efce5e",
   "metadata": {},
   "source": [
    "### 2.2 Assessing Model Accuracy\n",
    "Why is it necessary to introduce many different methods of statistical learning models rather than just a single *best* approach? *There is no free lunch in statistics*: no one method dominates over all others over all possible data sets. Hence it is an important task to decide for any given data set which method produces the best results. Selecting the best approach can be one of the most challenging parts of performing statistical learning in practice. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e581f6",
   "metadata": {},
   "source": [
    "### 2.2.1 Measuring the Quality of Fit\n",
    "In order to evaluate the performance of a statistical learning method on a given data set, we need some way to measure how well its predictions actually match the observed data. That is, we need to quantify the extent to which the predicted response value for a given observation is close to the true response value for that observation. For quantatiative response variables, the most commonly-used measure is the *mean squared error* (MSE), given by $$ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{f}(x_i))^2,$$ Therefore the MSE will be small if the predicted responses are close to the true responses, and will be large if the predicted and true values differ substantially. \n",
    "\n",
    "If the MSE is calculated using the training data, then it is refered to as the *training MSE*. In general, we do not care how well the method works on the training data but rather **we are interested in the accuracy of the predictions that we obtain when we apply our model to the unseen test data.** Therefore our goal is to choose the method that gives the lowest **test MSE**. \n",
    "\n",
    "Why not just use the model that results in the lowest training MSE? As model flexibility increases, training MSE will decrease but the test MSE may not. When a given method yeilds a small training MSE but a large test MSE, we are said to be **overfitting** the data. This happens because our model is working too hard to find patterns in the training data and may be picking up on some patterns that are just caused by chance rather than by the true properties of the unknown function $f$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b16a86",
   "metadata": {},
   "source": [
    "### 2.2.2 The Bias-Variance Trade-Off\n",
    "It can be shown that the expected test MSE, for a given value $x_0$, can be decomposed into the sum of three fundamental quantities: \n",
    "- The *variance* of $\\hat{f}(x_0)$\n",
    "- The squared *bias* of $\\hat{f}(x_0)$\n",
    "- The variance of the error term $\\epsilon$\n",
    "\n",
    "That is, $$ E(y_0 - \\hat{f}(x_0))^2 = Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\epsilon)$$\n",
    "\n",
    "The notation $E(y_0 - \\hat{f}(x_0))^2$ defines the *expected test MSE* and refers to the average test MSE we would obtain if we repeatedly estimated $f$ using a large number of training sets, and tested each at $x_0$. This tells us that in order to achieve the lowest expected test error, we need to select a statistical learning method that simultaneously achieves *low variance* and *low bias*.\n",
    "\n",
    "*Variance* refers to the amount by which $\\hat{f}$ would change if we estimated it using a different training set. Ideally the estimate for $f$ should not vary too much between different training sets. In general, more flexible models have higher variance. On the other hand, *bias* refers to the error that is introduced by approximating a real problem by a mathematical model. Generally, flexible models have less bias. Thus, the challenge lies in finding a method for which both the variance and the squared bias is low. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36437fab",
   "metadata": {},
   "source": [
    "### 2.2.3 The Classification Setting\n",
    "So far we have discussed mostly situations where the response variable is quantatative but there are many situations where we care about classification. Suppose that we seek to estimate $f$ on the basis of training observations ${(x_1, y_1), ..., (x_n, y_n)}$, where now $y_1, y_2, ..., y_n$ are qualitative. The most common approach for quantifying the accuracy of our estimate $\\hat{f}$ is the training *error rate*, the proportion of mistakes that are made if we apply our estimate $\\hat{f}$ to the training observations: $$\\frac{1}{n}\\sum_{i=1}^{n}I(y_i \\ne \\hat{y}_i)$$\n",
    "\n",
    "Here $\\hat{y}_i$ is the predicted label for the $i$th observation using $\\hat{f}$\n",
    "\n",
    "###### The Bayes Classifier\n",
    "It is possible to show that the test error rate is minimized by a very simple classifier that *assigns each observation to the most likely class, given its predictor values*. Then we should assign a test observationn with predictor vector $x_0$ to the class $j$ for which $$Pr(Y=j|X=x_0)$$ is largest. \n",
    "\n",
    "###### K-Nearest Neighbors\n",
    "In reality, we do not know the conditional distrubtion of $Y$ given $x$ and so computing the Bayes Classifier is impossible. K-*nearest neighbors* (KNN) is a common approach for classification where given $K$ and a test observation $x_0$, the KNN classifier first identifies the $K$ points in the training data that are closest to $x_0$ where: $$Pr(Y=j|X=x_0) = \\frac{1}{K}\\sum I(y_i = j)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978bfb9b",
   "metadata": {},
   "source": [
    "## Chapter 3. Linear Regression\n",
    "Simple linear regression is a straightforward approach for predicting a quantitative response $Y$ on the basis of a single predictor variable $X$. It assumes that there is approximately a linear relationship between $X$ and $Y$. We express this relationship mathematically as: $$Y \\approx \\beta_0 + \\beta_1X$$ where $\\beta_0$ and $\\beta_1$ are two unknown constants that represent the *slope* and *intercept* terms in the linear model. Together, $\\beta_0$ and $\\beta_1$ are known as the model *coefficients* or *paramters*. Once we use our training data to calculate esitmates for $\\beta_0$ and $\\beta_1$, which will be donoted as $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$, we can predict the output given an input: $$\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x$$ where $\\hat{y}$ indicates a prediction of $Y$ on the basis of $X=x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e8fc9",
   "metadata": {},
   "source": [
    "### 3.1.1 Estimating the Coefficients\n",
    "In practice, the true values of $\\beta_0$ and $\\beta_`1$ are unknown. So before we can predict outputs given inputs, we use the training data to estimate $\\beta_0$ and $\\beta_1$. Let ${(x_1, y_1), ..., (x_n, y_n)}$ represent $n$ observations pairs, each of which consists of a \"measurement\" $X$ and an \"output\" $Y$. Our goal is to obtain estimates $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ such that $$y_i \\approx \\hat{\\beta_0} + \\hat{\\beta_1}x_i$$ for each $i$ = 1, 2, ..., $n$. \n",
    "\n",
    "There are a number of ways of measuring *closeness* but the most common approach involves minimizing the *least squares* criterion. \n",
    "\n",
    "Let $\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1}x_i$ be the prediction for $Y$ based on the $i$th value of $X$. The let $e_i = y_i - \\hat{y_i}$ represent the $i$th *residual* - this is the difference between the $i$th observered response value (given in the training data) and the $i$th predicted response value (what would have been predicted by the model given input $x_i$). We now define the *residual sum of squares* (RSS) as $$RSS = e_1^2 + e_2^2 + ... + e_n^2$$ or equivalently as $$RSS = (y_1 - \\hat{y_1})^2 + (y_2 - \\hat{y_2})^2 + ... + (y_n - \\hat{y_n})^2$$ or equivalently as $$RSS = (y_1 - \\hat{\\beta_0} + \\hat{\\beta_1}x_1)^2 + (y_2 - \\hat{\\beta_0} + \\hat{\\beta_1}x_2)^2 + ... + (y_n - \\hat{\\beta_0} + \\hat{\\beta_1}x_n)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1dc53d",
   "metadata": {},
   "source": [
    "The least squares approach selects $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ that minimizes the RSS. Using some calculus, it can be shown that: $$\\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2},$$ $$\\hat{\\beta_0} = \\bar{y}-\\hat{\\beta_1}\\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d9306",
   "metadata": {},
   "source": [
    "### 3.1.2 Assessing the Accuracy of the Coefficient Estimates\n",
    "Now that $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ have been estiamted using the training data, we can assess the accuracy of these estiamtes assuming that the *true* relationship between $X$ and $Y$ takes the form $Y = f(X) + \\epsilon$ for some unknown function $f$, where $\\epsilon$ is a mean-zero random error term. In simple linear regression, we assume $f$ takes the form $Y = \\beta_0 + \\beta_1X + \\epsilon$.\n",
    "\n",
    "To answer the question \"How accurate is $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ as and estimate for $\\beta_0$ and $\\beta_1$\" we compute what is called the *standard error*. The standard error tells us the average amount that our estimate deviates from the true value. To compute standard errors with $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ we use the following formulas: $$SE(\\hat{\\beta_0})^2 = \\sigma^2[\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}]$$, $$SE(\\hat{\\beta_1})^2 = \\frac{\\sigma^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$ where $\\sigma^2 = Var(\\epsilon)$. Since in practice, the variance of $\\epsilon$ is not known (and thus also the standard deviation), we estimate $\\sigma$ as well and call it the *residual standard error*: $RSE = \\sqrt{\\frac{RSS}{(n-2)}}$.\n",
    "\n",
    "Standard errors can be used to compute *confidence intervals*. A 95% confidence interval is defined as a range of values such that with 95% probability, the range of numbers will contain the true value of the unknown parameter. For linear regression, the 95% confidence interval for $\\hat{\\beta_0}$ or $\\hat{\\beta_1}$ takes the form $$\\hat{\\beta_i} \\pm 2\\cdot SE(\\hat{\\beta_i})$$\n",
    "\n",
    "That is, there is approximately a 95% chance that the interval $$[\\hat{\\beta_i} - 2\\cdot SE(\\hat{\\beta_i}), \\hat{\\beta_i} + 2\\cdot SE(\\hat{\\beta_i})]$$ will contain the true value of $\\beta_i$. \n",
    "\n",
    "Standard errors can also be used to perform *hypothesis tests* on the coefficients. The most common hypothesis test involves testing the *null* hypothesis of $H_0$: There is no relationship between $X$ and $Y$ verse $H_a$: There is some relationship between $X$ and $Y$. Mathematically expressed: $$H_0: \\beta_1 = 0$$ verse $$H_a \\neq 0,$$ since if $\\beta_1 = 0$ then $Y = \\beta_0 + \\beta_1X + \\epsilon$ reduces to $Y = \\beta_0 + \\epsilon$ which is not dependent on $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda91f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
